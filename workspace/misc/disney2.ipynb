{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/danpasse/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     /Users/danpasse/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import json\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import itertools\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('omw-1.4')\n",
    "\n",
    "from gensim import corpora\n",
    "from gensim.models.ldamodel import LdaModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1\n",
    "\n",
    "- build dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cat_id': 391,\n",
       " 'job_id': 19757793040,\n",
       " 'step_1': ['* You are passionate about your area of expertise, deeply inquisitive and open minded, informed, but not limited, by your domain of expertise.\\n* You enjoy intellectual debate.\\n* You are comfortable guiding other team members but willing to get your hands dirty and help build research systems when needed\\n* You are driven to perform research that is not simply novel, but deeply impactful to the company and society have a deep desire to reduce the research to practice in the form of prototypes and technology demonstrators.\\n* You are excited by the platform provided by Disney to connect with children and guests of all ages to have a positive impact on the world.\\n* You have a deep sensitivity for ethical use of technology and data.\\n* You thrive in a fast-paced collaborative environment.\\n* You are self-directed and independent, but open to constructive feedback.\\n* You are a team player, able to work in collaborative interdisciplinary groups\\n* You are willing to take the time necessary to understand the business and adapt your knowledge to maximize the value of your contributions.\\n* You understand that communicating the value of your research to non-technical stakeholders is critical to continued investment.\\n* You understand that there are times when deep scientific rigor is necessary to validate a concept, and times when this is counterproductive, and are eager to discern the difference.\\n* You value sharing knowledge with the world but understand the need to drive and retain value in a private company.']}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents = []\n",
    "with open('../../data/disney/job_descriptions.json', 'r') as reader:\n",
    "  for description in json.loads(reader.read()):\n",
    "    items = [\n",
    "      item['text']\n",
    "      for item in description['sections']\n",
    "      if item['section'] == 'Basic Qualifications' or item['section'] == 'Preferred Qualifications'\n",
    "    ]\n",
    "\n",
    "    if len(items) == 0:\n",
    "      continue\n",
    "\n",
    "    qualification = {\n",
    "      'cat_id': description['cat_id'],\n",
    "      'job_id': description['job_id'],\n",
    "      'step_1': items\n",
    "    }\n",
    "\n",
    "    documents.append(qualification)\n",
    "\n",
    "documents[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2\n",
    "\n",
    "- text to sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* You are passionate about your area of expertise, deeply inquisitive and open minded, informed, but not limited, by your domain of expertise.\n",
      "* You enjoy intellectual debate.\n",
      "* You are comfortable guiding other team members but willing to get your hands dirty and help build research systems when needed\n",
      "* You are driven to perform research that is not simply novel, but deeply impactful to the company and society have a deep desire to reduce the research to practice in the form of prototypes and technology demonstrators.\n",
      "* You are excited by the platform provided by Disney to connect with children and guests of all ages to have a positive impact on the world.\n",
      "* You have a deep sensitivity for ethical use of technology and data.\n",
      "* You thrive in a fast-paced collaborative environment.\n",
      "* You are self-directed and independent, but open to constructive feedback.\n",
      "* You are a team player, able to work in collaborative interdisciplinary groups\n",
      "* You are willing to take the time necessary to understand the business and adapt your knowledge to maximize the value of your contributions.\n",
      "* You understand that communicating the value of your research to non-technical stakeholders is critical to continued investment.\n",
      "* You understand that there are times when deep scientific rigor is necessary to validate a concept, and times when this is counterproductive, and are eager to discern the difference.\n",
      "* You value sharing knowledge with the world but understand the need to drive and retain value in a private company.\n",
      "\n",
      "you are passionate about your area of expertise deeply inquisitive and open minded informed but not limited by your domain of expertise\n"
     ]
    }
   ],
   "source": [
    "def transform_text(text):\n",
    "  def clean_sentence(sentence):\n",
    "    sentence = re.sub(r'[`\\']', '', sentence)\n",
    "    sentence = re.sub(r'[,.!?:;\"]', ' ', sentence)\n",
    "    sentence = re.sub(r'\\s+', ' ', sentence)\n",
    "\n",
    "    return sentence.strip()\n",
    "\n",
    "  text = re.sub(r'(e\\.g\\.|\\/)', ' ', text)\n",
    "  text = re.sub(r'etc\\.', 'etc', text)\n",
    "  text = re.sub(r'[*â€¢\"()]', ' ', text)\n",
    "  text = re.sub(r'&', ' and ', text)\n",
    "\n",
    "  return [ clean_sentence(sentence) for sentence in sent_tokenize(text.lower()) ]\n",
    "\n",
    "for document in documents:\n",
    "  document['step_2'] = []\n",
    "  for section_text in document['step_1']:\n",
    "    document['step_2'].extend(transform_text(section_text))\n",
    "\n",
    "print(documents[0]['step_1'][0])\n",
    "print()\n",
    "print(documents[0]['step_2'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3\n",
    "\n",
    "- sentences to individual tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "you are passionate about your area of expertise deeply inquisitive and open minded informed but not limited by your domain of expertise\n",
      "\n",
      "['you', 'are', 'passionate', 'about', 'your', 'area', 'of', 'expertise', 'deeply', 'inquisitive', 'and', 'open', 'minded', 'informed', 'but', 'not', 'limited', 'by', 'your', 'domain', 'of', 'expertise']\n"
     ]
    }
   ],
   "source": [
    "for document in documents:\n",
    "  document['step_3'] = []\n",
    "  for sentence in document['step_2']:\n",
    "    document['step_3'].append(word_tokenize(sentence))\n",
    "  \n",
    "print(documents[0]['step_2'][0])\n",
    "print()\n",
    "print(documents[0]['step_3'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4\n",
    "\n",
    "- build ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['you', 'are', 'passionate', 'about', 'your', 'area', 'of', 'expertise', 'deeply', 'inquisitive', 'and', 'open', 'minded', 'informed', 'but', 'not', 'limited', 'by', 'your', 'domain', 'of', 'expertise']\n",
      "\n",
      "['you_are', 'are_passionate', 'passionate_about', 'about_your', 'your_area', 'area_of', 'of_expertise', 'expertise_deeply', 'deeply_inquisitive', 'inquisitive_and', 'and_open', 'open_minded', 'minded_informed', 'informed_but', 'but_not', 'not_limited', 'limited_by', 'by_your', 'your_domain', 'domain_of', 'of_expertise', 'you_are_passionate', 'are_passionate_about', 'passionate_about_your', 'about_your_area', 'your_area_of', 'area_of_expertise', 'of_expertise_deeply', 'expertise_deeply_inquisitive', 'deeply_inquisitive_and', 'inquisitive_and_open', 'and_open_minded', 'open_minded_informed', 'minded_informed_but', 'informed_but_not', 'but_not_limited', 'not_limited_by', 'limited_by_your', 'by_your_domain', 'your_domain_of', 'domain_of_expertise', 'you_are_passionate_about', 'are_passionate_about_your', 'passionate_about_your_area', 'about_your_area_of', 'your_area_of_expertise', 'area_of_expertise_deeply', 'of_expertise_deeply_inquisitive', 'expertise_deeply_inquisitive_and', 'deeply_inquisitive_and_open', 'inquisitive_and_open_minded', 'and_open_minded_informed', 'open_minded_informed_but', 'minded_informed_but_not', 'informed_but_not_limited', 'but_not_limited_by', 'not_limited_by_your', 'limited_by_your_domain', 'by_your_domain_of', 'your_domain_of_expertise', 'you_are_passionate_about_your', 'are_passionate_about_your_area', 'passionate_about_your_area_of', 'about_your_area_of_expertise', 'your_area_of_expertise_deeply', 'area_of_expertise_deeply_inquisitive', 'of_expertise_deeply_inquisitive_and', 'expertise_deeply_inquisitive_and_open', 'deeply_inquisitive_and_open_minded', 'inquisitive_and_open_minded_informed', 'and_open_minded_informed_but', 'open_minded_informed_but_not', 'minded_informed_but_not_limited', 'informed_but_not_limited_by', 'but_not_limited_by_your', 'not_limited_by_your_domain', 'limited_by_your_domain_of', 'by_your_domain_of_expertise']\n"
     ]
    }
   ],
   "source": [
    "n_gram_ranges = [2, 3, 4, 5]\n",
    "\n",
    "def format(tup):\n",
    "  return '_'.join(tup)\n",
    "\n",
    "for document in documents:\n",
    "  document['step_4'] = []\n",
    "  for tokens in document['step_3']:\n",
    "    sentence_grams = []\n",
    "    for n in n_gram_ranges:\n",
    "      sentence_grams.extend([ format(tup) for tup in nltk.ngrams(tokens, n)])\n",
    "    \n",
    "    document['step_4'].append(sentence_grams)\n",
    "\n",
    "print(documents[0]['step_3'][0])\n",
    "print()\n",
    "print(documents[0]['step_4'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5\n",
    "\n",
    "- final document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['you_are', 'are_passionate', 'passionate_about', 'about_your', 'your_area', 'area_of', 'of_expertise', 'expertise_deeply', 'deeply_inquisitive', 'inquisitive_and', 'and_open', 'open_minded', 'minded_informed', 'informed_but', 'but_not', 'not_limited', 'limited_by', 'by_your', 'your_domain', 'domain_of', 'of_expertise', 'you_are_passionate', 'are_passionate_about', 'passionate_about_your', 'about_your_area', 'your_area_of', 'area_of_expertise', 'of_expertise_deeply', 'expertise_deeply_inquisitive', 'deeply_inquisitive_and', 'inquisitive_and_open', 'and_open_minded', 'open_minded_informed', 'minded_informed_but', 'informed_but_not', 'but_not_limited', 'not_limited_by', 'limited_by_your', 'by_your_domain', 'your_domain_of', 'domain_of_expertise', 'you_are_passionate_about', 'are_passionate_about_your', 'passionate_about_your_area', 'about_your_area_of', 'your_area_of_expertise', 'area_of_expertise_deeply', 'of_expertise_deeply_inquisitive', 'expertise_deeply_inquisitive_and', 'deeply_inquisitive_and_open', 'inquisitive_and_open_minded', 'and_open_minded_informed', 'open_minded_informed_but', 'minded_informed_but_not', 'informed_but_not_limited', 'but_not_limited_by', 'not_limited_by_your', 'limited_by_your_domain', 'by_your_domain_of', 'your_domain_of_expertise', 'you_are_passionate_about_your', 'are_passionate_about_your_area', 'passionate_about_your_area_of', 'about_your_area_of_expertise', 'your_area_of_expertise_deeply', 'area_of_expertise_deeply_inquisitive', 'of_expertise_deeply_inquisitive_and', 'expertise_deeply_inquisitive_and_open', 'deeply_inquisitive_and_open_minded', 'inquisitive_and_open_minded_informed', 'and_open_minded_informed_but', 'open_minded_informed_but_not', 'minded_informed_but_not_limited', 'informed_but_not_limited_by', 'but_not_limited_by_your', 'not_limited_by_your_domain', 'limited_by_your_domain_of', 'by_your_domain_of_expertise']\n",
      "\n",
      "['you_are', 'are_passionate', 'passionate_about', 'about_your', 'your_area']\n"
     ]
    }
   ],
   "source": [
    "for document in documents:\n",
    "  document['step_5'] = []\n",
    "  for tokens in document['step_4']:\n",
    "    document['step_5'].extend(tokens)\n",
    "  \n",
    "print(documents[0]['step_4'][0])\n",
    "print()\n",
    "print(documents[0]['step_5'][:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6\n",
    "\n",
    "- filter out ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "qualifications = [ document['step_5'] for document in documents ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['ability_to' '264']\n",
      " ['experience_in' '128']\n",
      " ['in_a' '110']\n",
      " ['knowledge_of' '98']\n",
      " ['experience_with' '96']]\n",
      "\n",
      "[['respects_a_variety_of_voices' '1']\n",
      " ['a_variety_of_voices_identities' '1']\n",
      " ['variety_of_voices_identities_backgrounds' '1']\n",
      " ['of_voices_identities_backgrounds_experiences' '1']\n",
      " ['voices_identities_backgrounds_experiences_and' '1']]\n"
     ]
    }
   ],
   "source": [
    "bag_words = Counter(\n",
    "  itertools.chain(*qualifications)\n",
    ")\n",
    "\n",
    "n = 5\n",
    "print(np.array(bag_words.most_common(n)))\n",
    "print()\n",
    "print(np.array(bag_words.most_common()[-(n+1):-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## todo: tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "### todo: build list of stop words\n",
    "stop_words = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['you_are', 'are_passionate', 'passionate_about', 'about_your', 'your_area']\n",
      "\n",
      "['you_are', 'are_passionate', 'passionate_about', 'about_your', 'your_area']\n"
     ]
    }
   ],
   "source": [
    "for document in documents:\n",
    "  document['final'] = [ token for token in document['step_5'] if token not in stop_words ]\n",
    "  \n",
    "print(documents[0]['step_5'][:5])\n",
    "print()\n",
    "print(documents[0]['final'][:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 7\n",
    "\n",
    "- lda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents_to_process = [ document['final'] for document in documents ]\n",
    "dictionary = corpora.Dictionary(documents_to_process)\n",
    "document_term_matrix = [dictionary.doc2bow(doc) for doc in documents_to_process]\n",
    "\n",
    "model = LdaModel(\n",
    "  document_term_matrix,\n",
    "  num_topics=5,\n",
    "  id2word=dictionary,\n",
    "  passes=5,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['0'\n",
      "  '0.003*\"ability_to\" + 0.001*\"to_work\" + 0.001*\"experience_in\" + 0.001*\"in_a\" + 0.001*\"knowledge_of\" + 0.001*\"able_to\" + 0.001*\"experience_with\" + 0.001*\"understanding_of\" + 0.001*\"communication_skills\" + 0.001*\"years_of\"']\n",
      " ['1'\n",
      "  '0.002*\"ability_to\" + 0.001*\"familiarity_with\" + 0.001*\"experience_with\" + 0.001*\"knowledge_of\" + 0.001*\"in_a\" + 0.001*\"experience_in\" + 0.001*\"understanding_of\" + 0.001*\"to_work\" + 0.001*\"such_as\" + 0.000*\"you_are\"']\n",
      " ['2'\n",
      "  '0.001*\"ability_to\" + 0.001*\"you_have\" + 0.001*\"experience_in\" + 0.001*\"you_are\" + 0.001*\"understanding_of\" + 0.001*\"able_to\" + 0.001*\"communication_skills\" + 0.001*\"to_work\" + 0.001*\"in_a\" + 0.001*\"knowledge_of\"']\n",
      " ['3'\n",
      "  '0.002*\"ability_to\" + 0.001*\"experience_in\" + 0.001*\"in_a\" + 0.001*\"understanding_of\" + 0.001*\"experience_with\" + 0.001*\"knowledge_of\" + 0.001*\"you_have\" + 0.001*\"with_a\" + 0.000*\"years_of\" + 0.000*\"in_the\"']\n",
      " ['4'\n",
      "  '0.002*\"ability_to\" + 0.001*\"in_a\" + 0.001*\"knowledge_of\" + 0.001*\"experience_in\" + 0.001*\"experience_with\" + 0.001*\"understanding_of\" + 0.001*\"to_work\" + 0.001*\"familiarity_with\" + 0.000*\"such_as\" + 0.000*\"you_have\"']]\n"
     ]
    }
   ],
   "source": [
    "print(np.array(model.print_topics(num_topics=5, num_words=10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19757793040 -> (1, 0.99905574)\n",
      "26800277248 -> (0, 0.9989317)\n",
      "25793337456 -> (2, 0.997526)\n",
      "26601275040 -> (4, 0.9989188)\n",
      "24704474768 -> (0, 0.9989419)\n",
      "24704474480 -> (4, 0.9980505)\n",
      "24429981920 -> (1, 0.9992941)\n",
      "20042573200 -> (3, 0.9975338)\n",
      "27441961376 -> (3, 0.9974231)\n",
      "26304165456 -> (0, 0.99875724)\n",
      "24259248272 -> (0, 0.99342006)\n",
      "27629588832 -> (1, 0.99887717)\n",
      "27272804544 -> (4, 0.99707323)\n",
      "27266426816 -> (4, 0.99758)\n",
      "27506594224 -> (3, 0.9986497)\n",
      "26644660320 -> (0, 0.99641603)\n",
      "27699308208 -> (3, 0.998499)\n",
      "25947875248 -> (1, 0.99822646)\n",
      "27155015808 -> (3, 0.9978878)\n",
      "24573292192 -> (3, 0.9959056)\n",
      "24200527168 -> (1, 0.9986803)\n",
      "24170652720 -> (0, 0.9983058)\n",
      "23025374752 -> (4, 0.9975372)\n",
      "13560672608 -> (3, 0.99862653)\n",
      "27088782608 -> (0, 0.9963291)\n",
      "27077496880 -> (3, 0.99807096)\n",
      "27032698496 -> (1, 0.9979899)\n",
      "26606093104 -> (0, 0.99648935)\n",
      "26435839936 -> (2, 0.9987411)\n",
      "26435816656 -> (3, 0.99672234)\n",
      "26421625344 -> (1, 0.997339)\n",
      "26421612896 -> (0, 0.9965378)\n",
      "25804673536 -> (2, 0.9981198)\n",
      "25554435232 -> (1, 0.9970045)\n",
      "25131649216 -> (1, 0.99850196)\n",
      "25131645584 -> (3, 0.99774164)\n",
      "24641873728 -> (3, 0.99595267)\n",
      "24259253248 -> (4, 0.9993407)\n",
      "24200527440 -> (3, 0.9947958)\n",
      "23870703344 -> (2, 0.99749124)\n",
      "23333465824 -> (0, 0.998583)\n",
      "21407266064 -> (0, 0.9983455)\n",
      "17617622720 -> (2, 0.9987979)\n",
      "7255959040 -> (2, 0.99792814)\n",
      "25793359904 -> (1, 0.99480176)\n",
      "27457761616 -> (2, 0.99480337)\n",
      "26779119872 -> (3, 0.99687237)\n",
      "25922527760 -> (4, 0.99709344)\n",
      "23329326352 -> (0, 0.99706525)\n",
      "23183053712 -> (0, 0.9982717)\n",
      "16234915008 -> (1, 0.9879147)\n",
      "27611761792 -> (3, 0.99888724)\n",
      "26829879952 -> (2, 0.99907327)\n",
      "26724244240 -> (0, 0.9984007)\n",
      "26216960336 -> (3, 0.99921304)\n",
      "25351505360 -> (0, 0.99862415)\n",
      "24636972224 -> (4, 0.9982124)\n",
      "24636944096 -> (0, 0.998929)\n",
      "24588543440 -> (3, 0.998748)\n",
      "21286977968 -> (3, 0.9985447)\n",
      "27550252256 -> (2, 0.99838257)\n",
      "27506594064 -> (4, 0.997844)\n",
      "27200312192 -> (0, 0.99459547)\n",
      "27150046384 -> (1, 0.99862397)\n",
      "27082386416 -> (1, 0.99759275)\n",
      "26779112624 -> (0, 0.99758905)\n",
      "26761268944 -> (4, 0.9975995)\n",
      "26637704064 -> (0, 0.99879944)\n",
      "26637703936 -> (0, 0.9987775)\n",
      "26415117168 -> (1, 0.99815506)\n",
      "26288058352 -> (2, 0.9973243)\n",
      "26229767216 -> (0, 0.9987848)\n",
      "25854477200 -> (0, 0.99781734)\n",
      "25747556960 -> (2, 0.99838364)\n",
      "25747556816 -> (2, 0.9984585)\n",
      "25747556656 -> (2, 0.9984585)\n",
      "25137368128 -> (0, 0.9971476)\n",
      "25137360720 -> (0, 0.9971475)\n",
      "25001098864 -> (2, 0.99834234)\n",
      "24864114304 -> (1, 0.99837154)\n",
      "23892498304 -> (0, 0.9986934)\n",
      "20892574592 -> (1, 0.99837154)\n",
      "16360548592 -> (0, 0.46401948) (2, 0.53450966)\n",
      "5726106000 -> (0, 0.9982557)\n",
      "27855101056 -> (2, 0.99709105)\n",
      "27851186288 -> (3, 0.9976984)\n",
      "27851185408 -> (3, 0.9976723)\n",
      "27662461456 -> (1, 0.9975997)\n",
      "27635838304 -> (4, 0.99865544)\n",
      "27629594304 -> (3, 0.99852175)\n",
      "27625241008 -> (0, 0.9978858)\n",
      "27579278544 -> (3, 0.9980831)\n",
      "27559459632 -> (0, 0.9982401)\n",
      "27550252288 -> (2, 0.99801)\n",
      "27517914032 -> (2, 0.99644953)\n",
      "27506595200 -> (2, 0.9980252)\n",
      "27446648784 -> (3, 0.99906945)\n",
      "27266426752 -> (3, 0.9980587)\n",
      "27211199744 -> (4, 0.99814326)\n",
      "27168034960 -> (1, 0.9988188)\n",
      "27103436176 -> (1, 0.997599)\n",
      "26688731728 -> (0, 0.99707633)\n",
      "26387015248 -> (3, 0.99702734)\n",
      "26156952000 -> (4, 0.99785256)\n",
      "26156951968 -> (0, 0.997886)\n",
      "25854469776 -> (1, 0.9982396)\n",
      "25561189520 -> (4, 0.9977248)\n",
      "25561188240 -> (4, 0.9977248)\n",
      "25435107648 -> (1, 0.99886745)\n",
      "25137365136 -> (2, 0.99862754)\n",
      "25013171808 -> (0, 0.9984385)\n",
      "25013167568 -> (4, 0.9985762)\n",
      "25001098880 -> (1, 0.99872357)\n",
      "24573302128 -> (4, 0.9972691)\n",
      "24124709104 -> (2, 0.9988983)\n",
      "21392955472 -> (2, 0.9989608)\n",
      "20429183952 -> (1, 0.99573904)\n",
      "20143592448 -> (3, 0.9973147)\n",
      "582588672 -> (2, 0.99831825)\n",
      "4534138000 -> (0, 0.99667823)\n",
      "4534137840 -> (0, 0.99563986)\n",
      "4534137040 -> (1, 0.9964375)\n",
      "27780781936 -> (0, 0.99901885)\n",
      "27579281248 -> (0, 0.9990564)\n",
      "27478060016 -> (0, 0.9980773)\n",
      "27478059968 -> (0, 0.9968141)\n",
      "27478059952 -> (0, 0.99573463)\n",
      "27478059936 -> (0, 0.99698454)\n",
      "27225844592 -> (0, 0.9989339)\n",
      "27225844352 -> (0, 0.9985126)\n",
      "27155014240 -> (4, 0.99879897)\n",
      "27155014208 -> (4, 0.9988665)\n",
      "27064544304 -> (0, 0.9990537)\n",
      "26992390832 -> (3, 0.99870396)\n",
      "26713166704 -> (3, 0.9987222)\n",
      "26699601072 -> (3, 0.99944794)\n",
      "26688732128 -> (0, 0.9988585)\n",
      "26469543424 -> (0, 0.9990049)\n",
      "26469540640 -> (0, 0.9989715)\n",
      "26439104800 -> (0, 0.9989684)\n",
      "26200510976 -> (1, 0.9982923)\n",
      "26192258656 -> (4, 0.9987723)\n",
      "26139685376 -> (2, 0.9978789)\n",
      "24636969824 -> (0, 0.99783635)\n",
      "24573315312 -> (2, 0.999175)\n",
      "24525310416 -> (4, 0.9976597)\n",
      "24184282736 -> (2, 0.99892455)\n",
      "23086003744 -> (0, 0.9993868)\n",
      "22166953472 -> (0, 0.99877626)\n",
      "1803495712 -> (2, 0.99190384)\n",
      "17880405088 -> (2, 0.99888116)\n",
      "17501995776 -> (3, 0.9990593)\n",
      "27716762704 -> (1, 0.9989089)\n",
      "27550252720 -> (2, 0.99911165)\n",
      "24214078320 -> (1, 0.9987684)\n",
      "12128248944 -> (0, 0.99807125)\n",
      "27873373936 -> (0, 0.9972768)\n",
      "27861261296 -> (4, 0.99839544)\n",
      "27868816304 -> (4, 0.9983333)\n",
      "27873373664 -> (3, 0.9982743)\n",
      "27880153024 -> (4, 0.99838513)\n",
      "27873375440 -> (1, 0.9986383)\n",
      "27930209104 -> (2, 0.9988797)\n",
      "27934916224 -> (0, 0.99781156)\n",
      "27930208640 -> (4, 0.9973071)\n",
      "27991931456 -> (3, 0.99860424)\n",
      "27991924976 -> (4, 0.9966254)\n",
      "27996730304 -> (0, 0.9988011)\n",
      "28013695616 -> (2, 0.99829465)\n",
      "28018869648 -> (4, 0.99805343)\n",
      "28047612016 -> (3, 0.99836886)\n",
      "28087427296 -> (1, 0.99782884)\n"
     ]
    }
   ],
   "source": [
    "for document in documents:\n",
    "    job_id = document['job_id']\n",
    "    bow = dictionary.doc2bow(document['final'])\n",
    "    topic = model.get_document_topics(bow)\n",
    "\n",
    "    print(job_id, '->', *topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2304a4306d72a9fc8f52cfa19ebef60f8a2cea47ec9230cdf955b20fb7741e1a"
  },
  "kernelspec": {
   "display_name": "Python 3.9.1 ('monte': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
